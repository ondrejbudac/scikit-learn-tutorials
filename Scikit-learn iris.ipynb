{
 "metadata": {
  "name": "",
  "signature": "sha256:e0e2fbb7374b52b8cc82ef34d651fac78dd7147dfcdc9465b411b7e051778800"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets, cross_validation, svm, preprocessing, pipeline, metrics\n",
      "\n",
      "iris = datasets.load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We split the data to train and test data. The model is trained on the train data and its performance is measured on the test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train, data_test, target_train, target_test = cross_validation.train_test_split(\n",
      "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
      "classifier = svm.SVC(kernel='linear', C=1).fit(data_train, target_train)\n",
      "classifier.score(data_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "0.96666666666666667"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us use a $k$-fold cross-validation to tune a hyper-parameter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier_CV = svm.SVC(kernel='linear', C=1)\n",
      "scores = cross_validation.cross_val_score(classifier_CV, data_train, target_train, cv=5, scoring='f1_weighted')\n",
      "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 0.99 (+/- 0.05)\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us normalize the features first"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = preprocessing.StandardScaler().fit(data_train)\n",
      "data_train_transformed = scaler.transform(data_train)\n",
      "classifier_norm = svm.SVC(C=1).fit(data_train_transformed, target_train)\n",
      "data_test_transformed = scaler.transform(data_test)\n",
      "classifier_norm.score(data_test_transformed, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "0.93333333333333335"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now use a pipeline to make the processing easier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier_pipe = pipeline.make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
      "cross_validation.cross_val_score(classifier_pipe, data_train, target_train, cv=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "array([ 1.        ,  0.94736842,  1.        ,  0.94444444,  0.9375    ])"
       ]
      }
     ],
     "prompt_number": 60
    }
   ],
   "metadata": {}
  }
 ]
}